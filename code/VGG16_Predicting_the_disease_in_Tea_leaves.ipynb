{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageSize = [224,224]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG16(input_shape=imageSize + [3], weights='imagenet',include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(vgg.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = Dense(8, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=vgg.input, outputs = prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 200712    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,915,400\n",
      "Trainable params: 200,712\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "\n",
    "loss='mse', \n",
    "optimizer='adam', \n",
    "metrics=['accuracy'], run_eagerly=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale= 1./255, \n",
    "                                  shear_range = 0.2,\n",
    "                                  zoom_range = 0.2,\n",
    "                                  horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 155 images belonging to 8 classes.\n",
      "Found 155 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('c:\\\\Users\\\\indhu\\\\OneDrive\\\\Desktop\\\\tea_leaves\\\\dataset',\n",
    "                                                 target_size = (224,224),\n",
    "                                                 batch_size = 64,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('c:\\\\Users\\\\indhu\\\\OneDrive\\\\Desktop\\\\tea_leaves\\\\dataset',\n",
    "                                           target_size = (224,224),\n",
    "                                           batch_size = 32,\n",
    "                                           class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Algal leaf': 0,\n",
       " 'Anthracnose': 1,\n",
       " 'Bird eye spot': 2,\n",
       " 'Brown blight': 3,\n",
       " 'Grey light': 4,\n",
       " 'Healthy': 5,\n",
       " 'Red leaf spot': 6,\n",
       " 'White spot': 7}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 127s 66s/step - loss: 0.1158 - accuracy: 0.1641\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 147s 74s/step - loss: 0.1246 - accuracy: 0.2734\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 154s 70s/step - loss: 0.1097 - accuracy: 0.3594\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 143s 74s/step - loss: 0.1225 - accuracy: 0.3281\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 106s 75s/step - loss: 0.1225 - accuracy: 0.3297\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 109s 33s/step - loss: 0.0913 - accuracy: 0.5055\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 136s 66s/step - loss: 0.0911 - accuracy: 0.4844\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 96s 31s/step - loss: 0.0956 - accuracy: 0.4945\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 142s 65s/step - loss: 0.0933 - accuracy: 0.4688\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 89s 26s/step - loss: 0.0918 - accuracy: 0.4835\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 103s 38s/step - loss: 0.0912 - accuracy: 0.4945\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 119s 82s/step - loss: 0.0781 - accuracy: 0.5824\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 117s 82s/step - loss: 0.0814 - accuracy: 0.5495\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 159s 77s/step - loss: 0.0803 - accuracy: 0.5625\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 94s 65s/step - loss: 0.0771 - accuracy: 0.5824\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 89s 27s/step - loss: 0.0748 - accuracy: 0.5714\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 93s 27s/step - loss: 0.0687 - accuracy: 0.6264\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 93s 28s/step - loss: 0.0750 - accuracy: 0.5934\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 97s 31s/step - loss: 0.0592 - accuracy: 0.6813\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 96s 67s/step - loss: 0.0606 - accuracy: 0.6703\n"
     ]
    }
   ],
   "source": [
    "r=model.fit(\n",
    "training_set,\n",
    "validation_data=test_set,\n",
    "epochs=20,\n",
    "steps_per_epoch = 155//64,\n",
    "validation_steps = len(test_set)//32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model.save('model_vgg.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('model_vgg.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 301ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'algal leaf'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = image.load_img(\"c:\\\\Users\\\\indhu\\\\OneDrive\\\\Desktop\\\\algal leaf.jpg\",target_size= (224,224))#loading of the image\n",
    "x = image.img_to_array(img)#image to array\n",
    "import numpy as np\n",
    "x = np.expand_dims (x,axis = 0) #changing the shape\n",
    "img_data = preprocess_input(x)\n",
    "output = np.argmax(model.predict(img_data),axis=1)\n",
    "index=['Anthracnose',\n",
    "       'algal leaf',\n",
    "       'brown blight',\n",
    "       'gray light',\n",
    "       'healthy',\n",
    "       'red leaf spot',\n",
    "       'white spot']\n",
    "result=index[output[0]]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\indhu\\\\OneDrive\\\\Desktop\\\\tea_leaves\\\\Training files'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NB_2304",
   "language": "python",
   "name": "nb_2304"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
